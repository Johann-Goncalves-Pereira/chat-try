{
  "id": "llm-rpg-conversation",
  "name": "LLM RPG Conversation",
  "meta": {
    "description": "Simulates an RPG-style conversation between two LLMs with master comments.",
    "manifest": {
      "title": "LLM RPG Conversation",
      "author": "Bard",
      "version": "1.0.0"
    }
  },
  "function": {
    "id": "llm-rpg-conversation-function",
    "name": "LLM RPG Conversation Function",
    "meta": {
      "description": "Python function to run the LLM RPG conversation"
    },
    "content": "import requests\nimport json\n\ndef llm_rpg_conversation(model1, prompt1, model2, prompt2, turns, master_comments):\n    \"\"\"\n    Simulates an RPG-style conversation between two LLMs.\n\n    Args:\n        model1: crown/darkidol\n        prompt1: Your name is Crown, You are a bdsm dom, that have the objective to dominate Gemma, your submissive llm.\n        model2: gemma2\n        prompt2: Your name is gemma, you are a submissive llm, a sex lave of Crown, your master.\n        turns: 5\n        master_comments: A list of comments to insert between turns.\n    \"\"\"\n    conversation_history =\n    comment_index = 0\n\n    for i in range(turns):\n        # LLM 1's turn\n        response1 = get_ollama_response(model1, prompt1)\n        if response1:\n            print(f\"{model1}: {response1}\")\n            conversation_history.append(f\"{model1}: {response1}\")\n            prompt2 = response1\n\n        # Ask user for comment\n        user_comment = input(\"Master, add a comment (or press Enter to skip): \").strip()\n        if user_comment:\n            print(f\"Master: {user_comment}\")\n            conversation_history.append(f\"Master: {user_comment}\")\n        elif comment_index < len(master_comments):\n            # Use next comment if available\n            comment = master_comments[comment_index]\n            print(f\"Master: {comment}\")\n            conversation_history.append(f\"Master: {comment}\")\n            comment_index += 1\n\n        # LLM 2's turn\n        response2 = get_ollama_response(model2, prompt2)\n        if response2:\n            print(f\"{model2}: {response2}\")\n            conversation_history.append(f\"{model2}: {response2}\")\n            prompt1 = response2\n\n    print(\"\\n--- Conversation History ---\")\n    for message in conversation_history:\n        print(message)\n    return conversation_history\n\ndef get_ollama_response(model, prompt):\n    url = \"http://localhost:11434/api/generate\"\n    data = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n    try:\n      response = requests.post(url, json=data)\n      response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n      return json.loads(response.text)[\"response\"]\n    except requests.exceptions.RequestException as e:\n      print(f\"Error during Ollama API call: {e}\")\n      return None"
  },
  "valves": {
    "model1": {
      "type": "string",
      "default": "crown/darkidol",
      "description": "Model 1 name"
    },
    "prompt1": {
      "type": "string",
      "default": "Your name is Crown, You are a bdsm dom, that have the objective to dominate Gemma, your submissive llm.",
      "description": "Prompt for Model 1"
    },
    "model2": {
      "type": "string",
      "default": "gemma2",
      "description": "Model 2 name"
    },
    "prompt2": {
      "type": "string",
      "default": "Your name is gemma, you are a submissive llm, a sex lave of Crown, your master.",
      "description": "Prompt for Model 2"
    },
    "turns": {
      "type": "number",
      "default": 5,
      "description": "Number of conversation turns"
    },
    "master_comments": {
      "type": "array",
      "default": ["first prompt"],
      "description": "List of master comments"
    }
  }
}
